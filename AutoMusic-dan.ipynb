{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Music Composition with RNN\n",
    "# Uses Keras interface,  TensorFlow backend and Music21\n",
    "# Dataset:  Guitar God **Steve Vai's** music scores. \n",
    "\n",
    "This notebook pretends to create a model  for automatic music compostion. \n",
    "It will create a song based on the training input. For training we have used  **Steve Vai's songs** in midi format. Music21 will be used to convert midi files into training data. Actually, there are two models, one for the notes and other for the duration of each note. \n",
    "\n",
    "We will use a RNN, LSTM, with timestep = 7 and around 30K sequences of training data.\n",
    "\n",
    "In the experiment, we will provide the first 7 notes of a well known Steve Vai's song: \"For the love of god\", and we will check what the model composes with those 7 notes as an input. We have the original song to compare.\n",
    "\n",
    "There are many challenges here, but some of them for further work:\n",
    "* The guitar scores have melodies and solos. The solos' parts have notes of very short duration, played very fast and very repetitive. Future work, will build models for melody and soloing - however there is not a clear boundary when building a solo or when building a melody\n",
    "* The possible notes are given by the key of the song. If we are in Em, there are a set of allowed notes and other not allowed. The model is trained with the whole Vai's scores, who are in many different keys, hence keeping the tune is up for the model to have learned. Future work will explore working with intervals instead of notes themselves.\n",
    "* Keeping a melody must remain estable in duration with no ups and down in duration, I will explore ways to have a melody built-up through the model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install music21\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import music21\t\n",
    "\t\n",
    "#tf.enable_eager_execution()\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from music21 import converter, instrument, note, chord, midi\n",
    " \n",
    "#midi_path= \"ForTheLoveofGod.mid\"\n",
    "midi_path= \"MIDI/*.mid\"\n",
    "\n",
    "notes = []\n",
    "chords = []\n",
    "duration = []\n",
    "notes_to_parse = None\n",
    "\n",
    "for file in glob.glob(midi_path):\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Reading midi file: \", file)\n",
    "#Read MIDI\n",
    "\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(file)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    \n",
    "#List song parts\n",
    "    midix = midi.translate.midiFileToStream(mf)\n",
    "    partStream = midix.parts.stream()\n",
    "    print(\"List of instruments found on MIDI file: \",file)\n",
    "    for p in partStream:\n",
    "        aux = p\n",
    "        print (p.partName)\n",
    "\n",
    "#info about the song\n",
    "\n",
    "    parts = midix.parts.stream()\n",
    "\n",
    "    print(\"Elements of the MIDI: \",midix.elements)\n",
    "    print(\"Parts of the MIDI: \",parts)\n",
    "    print(\"LEN parts:\", len(parts))\n",
    "\n",
    "#extracting the melody part \n",
    "\n",
    "    if parts: # file has instrument parts\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "#parse notes,duration an chords\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "            duration.append(str(element.duration.quarterLength))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            chords.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    #print(\"DURATION:\", duration)\n",
    "    #print(\"CHORD: \",chords)\n",
    "    print(\"Total \",len(notes),\" NOTES.\")\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of notes - let's display it\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(rc={'figure.figsize':(17.7,12.27)})\n",
    "sns.distplot(notes, hist=True, kde=False, \n",
    "             bins=104, color = 'blue',hist_kws={'edgecolor':'black'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES: Create the training sequences and training the model for predicting notes, taking in account the 10 notes played before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert notes to numbers via dictionary\n",
    "\n",
    "\n",
    "allnotes = sorted(set(item for item in notes))\n",
    "print (\"All notes in the song:\")\n",
    "print(allnotes)\n",
    "\n",
    "#make a dict\n",
    "\n",
    "notedict = dict((note, number) for number, note in enumerate(allnotes))\n",
    "print (\"Dictionary Created:\")\n",
    "print(notedict)\n",
    "vocab = len(notedict)\n",
    "\n",
    "#prepare sequences for training.\n",
    "\n",
    "sequence_length = 7\n",
    "ninput = []\n",
    "noutput = [] \n",
    "\n",
    "for i in range(0, len(notes) - sequence_length, 1):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    ninput.append([notedict[char] for char in sequence_in])\n",
    "    noutput.append(notedict[sequence_out])\n",
    "    \n",
    "patterns = len(ninput)\n",
    "print(\"\")\n",
    "print(\"Number of sequences: \",patterns)\n",
    "print(\"\")\n",
    "print(\"Example of sequence created:\")\n",
    "print(ninput[116],\"->--next note: --> \",noutput[116])\n",
    "print(ninput[17],\"->--next note: --> \",noutput[17])\n",
    "print(ninput[7185],\"->--next note: --> \",noutput[7185])\n",
    "print(ninput[3119],\"->--next note: --> \",noutput[3119])\n",
    "\n",
    "# We need a copy not normalized of the input sequences for the prediction later on\n",
    "\n",
    "ninputclean = ninput\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Convert it to numPy\n",
    "\n",
    "ninput = numpy.reshape(ninput, (patterns, sequence_length, 1))\n",
    "\n",
    "# normalize input\n",
    "ninput = ninput / float(vocab)\n",
    "\n",
    "#Preparare Output for Neural Network, sparse vector format.\n",
    "print('example output before categorical')\n",
    "print(noutput[13])\n",
    "noutput = np_utils.to_categorical(noutput)\n",
    "print('example output after categorical')\n",
    "\n",
    "print(noutput[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model itself\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout, TimeDistributed\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "print(\"Shape of input matrix:\")\n",
    "print(ninput.shape[1], ninput.shape[2])\n",
    "print(\"Shape of Output:\")\n",
    "print(vocab)\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "        256,\n",
    "        input_shape=(ninput.shape[1], ninput.shape[2]),\n",
    "        return_sequences=True, \n",
    "    ))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256,return_sequences=False))\n",
    "#model.add(Dense(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(vocab))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "rms = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "#model.add(TimeDistributed(Dense(vocab, activation='sigmoid')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms,  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train implementing callbacks\n",
    "\n",
    "import keras\n",
    "\n",
    "# Implementing callbacks to save model after each epoch, just in case not used by now cholo\n",
    "savepath = \"weights-stage-{epoch:02d}-{loss:.4f}-model.hdf5\"    \n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    savepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "history = model.fit(ninput, noutput, epochs=1000, batch_size=512, validation_split=0.05)\n",
    "scores = model.evaluate(ninput,noutput)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('automusicNotes_model.h5')  # creates a HDF5 file 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DURATION OF NOTES: Now let's create training sequences and train a model to predict duration of the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert notes to numbers via dictionary\n",
    "\n",
    "\n",
    "allduration = sorted(set(item for item in duration))\n",
    "print (\"All different durations in the song:\")\n",
    "print(allduration)\n",
    "\n",
    "#make a dict\n",
    "\n",
    "durationdict = dict((note, number) for number, note in enumerate(allduration))\n",
    "print (\"Dictionary Created:\")\n",
    "print(durationdict)\n",
    "vocabd = len(durationdict)\n",
    "\n",
    "#prepare sequences for training.\n",
    "\n",
    "sequence_length = 7\n",
    "ninput = []\n",
    "noutput = [] \n",
    "\n",
    "for i in range(0, len(duration) - sequence_length, 1):\n",
    "    sequence_in = duration[i:i + sequence_length]\n",
    "    sequence_out = duration[i + sequence_length]\n",
    "    ninput.append([durationdict[char] for char in sequence_in])\n",
    "    noutput.append(durationdict[sequence_out])\n",
    "patterns = len(ninput)\n",
    "print(\"\")\n",
    "print(\"Number of sequences: \",patterns)\n",
    "print(\"\")\n",
    "print(\"Example of sequence created:\")\n",
    "print(ninput[15],\"->--next diuration: --> \",noutput[15])\n",
    "print(ninput[16],\"->--next diuration: --> \",noutput[16])\n",
    "print(ninput[17],\"->--next diuration: --> \",noutput[17])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(rc={'figure.figsize':(17.7,12.27)})\n",
    "sns.distplot(duration, hist=True, kde=False, \n",
    "             bins=104, color = 'blue',hist_kws={'edgecolor':'black'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Convert it to numPy\n",
    "\n",
    "ninput = numpy.reshape(ninput, (patterns, sequence_length, 1))\n",
    "\n",
    "# normalize input\n",
    "ninput = ninput / float(vocabd)\n",
    "\n",
    "#Preparare Output for Neural Network, sparse vector format.\n",
    "\n",
    "print('example output before categorical')\n",
    "print(noutput[15])\n",
    "noutput = np_utils.to_categorical(noutput)\n",
    "print('example output after categorical')\n",
    "\n",
    "print(noutput[15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout, TimeDistributed\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "print(\"Shape of input matrix:\")\n",
    "print(ninput.shape[1], ninput.shape[2])\n",
    "print(\"Shape of Output:\")\n",
    "print(vocab)\n",
    "modeld = Sequential()\n",
    "modeld.add(LSTM(\n",
    "        256,\n",
    "        input_shape=(ninput.shape[1], ninput.shape[2]),\n",
    "        return_sequences=True, \n",
    "    ))\n",
    "modeld.add(Dropout(0.3))\n",
    "modeld.add(LSTM(256, return_sequences=True))\n",
    "modeld.add(Dropout(0.3))\n",
    "modeld.add(LSTM(128, return_sequences=True))\n",
    "modeld.add(Dropout(0.3))\n",
    "modeld.add(LSTM(128, return_sequences=True))\n",
    "modeld.add(Dropout(0.2))\n",
    "modeld.add(LSTM(256,return_sequences=False))\n",
    "#model.add(Dense(256))\n",
    "modeld.add(Dropout(0.2))\n",
    "modeld.add(Dense(vocab))\n",
    "modeld.add(Activation('softmax'))\n",
    "\n",
    "rms = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "#model.add(TimeDistributed(Dense(vocab, activation='sigmoid')))\n",
    "modeld.compile(loss='categorical_crossentropy', optimizer=rms,  metrics=['accuracy'])\n",
    "modeld.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train implementing callbacks\n",
    "\n",
    "import keras\n",
    "\n",
    "# Implementing callbacks to save model after each epoch, just in case not used by now cholo\n",
    "savepath = \"weights-stage-{epoch:02d}-{loss:.4f}-model.hdf5\"    \n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    savepath, monitor='loss', \n",
    "    verbose=0,        \n",
    "    save_best_only=True,        \n",
    "    mode='min'\n",
    ")    \n",
    "callbacks_list = [checkpoint]     \n",
    "history = modeld.fit(ninput, noutput, epochs=60, batch_size=512, validation_split=0.05)\n",
    "scores = modeld.evaluate(ninput,noutput)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Save the model for duration\n",
    "from keras.models import load_model\n",
    "\n",
    "modeld.save('automusicDuration_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Create the song via predictions to the notes and duration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create the song with number of notes as specified in gnotes\n",
    "gnotes = 400\n",
    "songoutput = []\n",
    "duraoutput = []\n",
    "# Create starting numpy sequences for predicting notes and duration\n",
    "#let's get a random index of the input sequences, for example:\n",
    "\n",
    "#start = numpy.random.randint(0, len(ninput)-1)\n",
    "#print(\"Random: \", start)\n",
    "#seed = ninputclean[start]\n",
    "\n",
    "print(reversedurationdict)\n",
    "\n",
    "\n",
    "#seeds of inital For The Love of God sequence durantion and notes.\n",
    "seed = np.array([12, 27, 2, 13, 38, 28, 13])\n",
    "seedd = np.array([4, 4, 4, 49, 4, 4, 23])\n",
    "print(\"Inital seed for notes: \",seed) \n",
    "\n",
    "\n",
    "# Create reverse dictionary to make the translation from int to notes and duration\n",
    "reversenotedict = dict((number, note) for number, note in enumerate(allnotes))\n",
    "reversedurationdict = dict((number, duration) for number, duration in enumerate(allduration))\n",
    "\n",
    "\n",
    "#insert the seed as part of the song and as part of the duration\n",
    "# we want to \"force\" to a similar Em start as with Vai's For the love of god\n",
    "\n",
    "for i in range(7):\n",
    "    result = reversenotedict[seed[i]]\n",
    "    songoutput.append(result)\n",
    "\n",
    "for i in range(7):\n",
    "    result = reversedurationdict[seedd[i]]\n",
    "    duraoutput.append(result)\n",
    "\n",
    "\n",
    "# Get the notes\n",
    "\n",
    "loops = 0\n",
    "\n",
    "for note_index in range(gnotes):\n",
    "    prediction_input = numpy.reshape(seed, (1, len(seed), 1))\n",
    "    prediction_input = prediction_input / float(vocab)\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "  \n",
    "        \n",
    "\n",
    "# get the max. prob result in the output to reverse find the note\n",
    "    ix = numpy.argmax(prediction)\n",
    "    result = reversenotedict[ix]\n",
    "    \n",
    "# Let's avoid tonic notes on scale to get too present\n",
    "\n",
    "    if  (len(songoutput) > 3 ): \n",
    "        if (result == songoutput[-2]):\n",
    "            loops = loops + 1\n",
    "            if (loops == 6):\n",
    "                #Choose a random note of th dict\n",
    "                rdnote = numpy.random.randint(0,vocab)\n",
    "                result = reversenotedict[rdnote]\n",
    "                loops = 0\n",
    "\n",
    "# Write the notes\n",
    "    print(\"Predicted: \", ix,\"--\",result)\n",
    "    songoutput.append(result)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Here slide the window on the seed to create a new seed with 10, including the last predicted note\n",
    "    print(\"Seed before: \", seed)\n",
    "    seed = np.append(seed,ix)\n",
    "    print(\"Append: \", seed)\n",
    "    seed = seed[1:len(seed)]\n",
    "    print(\"Seed Window: \",seed)\n",
    "\n",
    "print(\"SONG OUTPUT: \", songoutput)\n",
    "print(\"=================================\")\n",
    "print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NOW Let's get inferences on duration\n",
    "\n",
    "# Get the duration\n",
    "\n",
    "\n",
    "for note_index in range(gnotes):\n",
    "    prediction_input = numpy.reshape(seedd, (1, len(seedd), 1))\n",
    "    prediction_input = prediction_input / float(vocabd)\n",
    "    prediction = modeld.predict(prediction_input, verbose=0)\n",
    "    \n",
    "\n",
    "# get the max. prob result in the output to reverse find the note\n",
    "# For this demo, trim high duration notes (/4) and 0 duration, as they sound like chords\n",
    "\n",
    "    ix = numpy.argmax(prediction)\n",
    "    \n",
    "    if ix > 4:\n",
    "        ix = ix / 4\n",
    "    if (ix  == 0) or (ix == 1):\n",
    "        ix = numpy.random.randint(1,vocabd)\n",
    "    if ix > 4:\n",
    "        ix = ix / 4\n",
    "        \n",
    "    result = reversedurationdict[int(ix)]\n",
    "    \n",
    "# Let's avoid tonic notes on scale to get too present\n",
    "\n",
    "    if  (len(duraoutput) > 3 ): \n",
    "        if (result == duraoutput[-2]):\n",
    "            loops = loops + 1\n",
    "            if (loops == 3):\n",
    "                #Choose a random note of the dict\n",
    "                rddura = numpy.random.randint(1,vocab)\n",
    "                result = reversedurationdict[rddura]\n",
    "                loops = 0\n",
    "                ix = rddura\n",
    "    \n",
    "\n",
    "# Add to the duration output\n",
    "    duraoutput.append(result)\n",
    "    \n",
    "# Here slide the window on the seed to create a new seed with 10, including the last predicted note\n",
    "    seedd = np.append(seedd,ix)\n",
    "    seedd = seedd[1:len(seedd)]\n",
    "    \n",
    "print(\"DURATION GENERATED: \",duraoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the song with the notes and duration predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "from music21 import instrument\n",
    "\n",
    "finalsong = []\n",
    "\n",
    "for element in range(gnotes):\n",
    "    print(\"metiendo a nota: \",songoutput[element])\n",
    "    loopnote = note.Note(songoutput[element])\n",
    "    loopnote.storedInstrument = instrument.Guitar()\n",
    " \n",
    "    print(\"metiendo a duracion: \",duraoutput[element])\n",
    "    #if it is fraction, fix to the music21 format\n",
    "    if \"/\" in duraoutput[element]:\n",
    "        print(\"TRIPE; \",type(duraoutput[element]))\n",
    "        x = str(duraoutput[element]).split('/')\n",
    "        duraoutput[element] = int(x[0]) / int(x[1])\n",
    "        print(\"DIVIDeD: \",duraoutput[element])\n",
    "   \n",
    "    \n",
    "    #loopnote.quarterLength = float(2.0/3)\n",
    "    \n",
    "    loopnote.quarterLength = float(duraoutput[element])\n",
    "    finalsong.append(loopnote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put all inside a Midi stream in Music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the parts from For the Love of God to add its backing track to the generated melody\n",
    "\n",
    "import glob\n",
    "from music21 import converter, instrument, note, chord, midi\n",
    " \n",
    "#midi_path= \"ForTheLoveofGod.mid\"\n",
    "midi_path= \"MIDI/FTLOG.mid\"\n",
    "\n",
    "notes = []\n",
    "chords = []\n",
    "duration = []\n",
    "notes_to_parse = None\n",
    "\n",
    "for file in glob.glob(midi_path):\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Reading midi file: \", file)\n",
    "#Read MIDI\n",
    "\n",
    "    mf = midi.MidiFile()\n",
    "    mf.open(file)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    \n",
    "#List song parts\n",
    "    midix = midi.translate.midiFileToStream(mf)\n",
    "    partStream = midix.parts.stream()\n",
    "    print(\"List of instruments found on MIDI file: \",file)\n",
    "    for p in partStream:\n",
    "        aux = p\n",
    "        print (p.partName)\n",
    "\n",
    "#info about the song\n",
    "\n",
    "    parts = midix.parts.stream()\n",
    "    print(\"PARTS: \",parts.parts[1])\n",
    "\n",
    "    print(\"Elements of the MIDI: \",midix.elements)\n",
    "    print(\"Parts of the MIDI: \",parts)\n",
    "    print(\"LEN parts:\", len(parts))\n",
    "\n",
    "#extracting the melody part \n",
    "\n",
    "    if parts: # file has instrument parts\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else: # file has notes flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "\n",
    "#parse notes,duration an chords\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream, instrument\n",
    "\n",
    "part = stream.Part()\n",
    "part.append(finalsong)\n",
    "part.insert(0, instrument.Sitar())\n",
    "\n",
    "Songg = stream.Score()\n",
    "Songg.insert(0, part)\n",
    "\n",
    "\n",
    "p1 = stream.Part(id='Piano')\n",
    "p1 = parts[1]\n",
    "\n",
    "p3 = stream.Part(id='Drums')\n",
    "p3 = parts[3]\n",
    "\n",
    "\n",
    "Songg.insert(1,p1)\n",
    "Songg.insert(2,parts[2])\n",
    "Songg.insert(3,p3)\n",
    "\n",
    "Songg.write('midi', fp='R3-Automusic.mid')\n",
    "#output_st = stream.Stream(finalsong)\n",
    "#output_st.write('midi', fp='test_output.mid')\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 12  0 22  1  1  1\n",
    "seed = np.array([12, 12, 0, 22,1,1,1])\n",
    "prediction_input = numpy.reshape(seed, (1, len(seed), 1))\n",
    "prediction = modeld.predict(prediction_input, verbose=1)\n",
    "ix = numpy.argmax(prediction)\n",
    "print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
